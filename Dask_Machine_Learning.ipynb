{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kwasi\\Anaconda3\\envs\\Thinkful\\lib\\site-packages\\dask\\array\\random.py:27: FutureWarning: dask.array.random.doc_wraps is deprecated and will be removed in a future version\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "from dask.distributed import Client, progress\n",
    "from dask_ml.model_selection import train_test_split\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=4, threads_per_worker=2, memory_limit='2GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:55595</li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>8.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:55595' processes=4 threads=8, memory=8.00 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the data into Dask dataframe\n",
    "df = dd.read_csv('creditcard.csv', dtype={'Time': 'float64'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In this task, you'll train several machine learning models from scikit-learn using Dask as the backend of joblib. This time, you need to use all the variables except Class as your feature set. Class variable will be your target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=3\n",
       "    int64\n",
       "      ...\n",
       "      ...\n",
       "      ...\n",
       "Name: Class, dtype: int64\n",
       "Dask Name: split, 3 tasks"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is our feature set\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "\n",
    "# This is our target variable\n",
    "Y = df[\"Class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# Since our data can fit into memory\n",
    "# we persist them to the RAM.\n",
    "X_train.persist()\n",
    "X_test.persist()\n",
    "y_train.persist()\n",
    "y_test.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression training score is:  0.8724045225424578\n",
      "Logistic regression test score is:  0.8194939574931844\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    lr.fit(X_train.compute(), y_train.compute())\n",
    "    \n",
    "preds_train = lr.predict(X_train.values.compute())\n",
    "preds_test = lr.predict(X_test.values.compute())\n",
    "\n",
    "print(\"Logistic regression training score is: \", roc_auc_score(preds_train, y_train.values.compute()))\n",
    "print(\"Logistic regression test score is: \", roc_auc_score(preds_test, y_test.values.compute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting tree training score is:  0.9226840622440823\n",
      "Gradient boosting tree test score is:  0.8653453343565268\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    gbc.fit(X_train.compute(), y_train.compute())\n",
    "    \n",
    "preds_train = gbc.predict(X_train.values.compute())\n",
    "preds_test = gbc.predict(X_test.values.compute())\n",
    "\n",
    "print(\"Gradient boosting tree training score is: \", roc_auc_score(preds_train, y_train.values.compute()))\n",
    "print(\"Gradient boosting tree test score is: \", roc_auc_score(preds_test, y_test.values.compute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest training score is:  1.0\n",
      "Random forest test score is:  0.976342033669618\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    rfc.fit(X_train.compute(), y_train.compute())\n",
    "    \n",
    "preds_train = rfc.predict(X_train.values.compute())\n",
    "preds_test = rfc.predict(X_test.values.compute())\n",
    "\n",
    "print(\"Random forest training score is: \", roc_auc_score(preds_train, y_train.values.compute()))\n",
    "print(\"Random forest test score is: \", roc_auc_score(preds_test, y_test.values.compute()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results of your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results, the best performing model is the random forest. It's performance in both training and test sets are higher than those of the logistic regression and gradient boosting tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
